Animal Sound Classifier

A machine learning pipeline for classifying animal sounds using audio preprocessing, feature extraction, model training, and evaluation.
This project is designed for hands-on learning, with simple, modular Python scripts and Jupyter notebooks.

ğŸ“ Project Structure
animal-sound-classifier/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Unprocessed audio files and dataset metadata
â”‚   â”œâ”€â”€ processed/         # Cleaned & normalized audio
â”‚   â””â”€â”€ README.md          # Data sources + preprocessing notes
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01-data-exploration.ipynb  # For initial dataset inspection
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processing.py # Audio cleaning, augmentation, feature extraction
â”‚   â”œâ”€â”€ model.py           # Model definitions (CNN, etc.)
â”‚   â”œâ”€â”€ train.py           # Training loop
â”‚   â”œâ”€â”€ evaluate.py        # Evaluation & confusion matrix
â”‚   â””â”€â”€ predict.py         # Predict labels for new audio
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_model.pth     # Saved PyTorch model
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_data_processing.py    # Unit tests (optional)
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â””â”€â”€ LICENSE

ğŸš€ Project Overview

This project aims to build a supervised ML model that can classify animal sounds (e.g., dogs, cats, birds, cows, etc.).
It includes:

Audio preprocessing (trimming, normalization, denoising)

Feature extraction (MFCCs, spectrograms)

Model training using convolutional neural networks

Evaluation with metrics & confusion matrix

Inference on new sound samples

This repo is structured to follow best practices in ML engineering.

ğŸ› ï¸ Setup Instructions
1. Clone the Repository
git clone https://github.com/your-username/animal-sound-classifier.git
cd animal-sound-classifier

2. Create a Virtual Environment (optional but recommended)
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate     # Windows

3. Install Dependencies
pip install -r requirements.txt

ğŸ§ Data

Place your audio dataset inside:

data/raw/


After preprocessing, cleaned data will appear in:

data/processed/


You can document your dataset sources inside:

data/README.md

ğŸ“Š Notebooks

Use Jupyter to explore and understand your data:

jupyter notebook notebooks/01-data-exploration.ipynb

ğŸ§© Code Modules
ğŸ”¹ data_processing.py

Audio loading

Noise reduction

MFCC extraction

Spectrogram generation

Normalization

Data augmentation

ğŸ”¹ model.py

CNN architectures for audio classification

Helper functions for building PyTorch models

ğŸ”¹ train.py

Training loop

Data loaders

Loss functions & optimizers

Model checkpoint saving

ğŸ”¹ evaluate.py

Accuracy, precision, recall, F1

Confusion matrix visualization

ğŸ”¹ predict.py

Load trained model

Run inference on new audio file

Output predicted label

ğŸ‹ï¸ Training the Model

Example training command:

python src/train.py --epochs 20 --batch-size 32 --lr 0.001


Your best model will be saved in:

/models/best_model.pth

ğŸ” Running Inference
python src/predict.py --audio path/to/file.wav

ğŸ§ª Testing

If using unit tests:

pytest

ğŸ“„ License

This project is licensed under the MIT License.
Feel free to use, modify, and distribute.

ğŸ¤ Contributing

Feel free to open issues or submit pull requests!
This project is designed for personal learning, so improvements are welcome.
